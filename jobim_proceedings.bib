@article{breiman:2001,
  author  = {Breiman, L.},
  pages   = {5--32},
  title   = {Random Forests},
  journal = {Machine Learning},
  volume  = {45},
  number  = {1},
  year    = {2001}
}

@book{breiman:etal:1984,
  title     = {Classification and Regression Trees},
  author    = {Breiman, L. and Friedman, J. and Stone, C. J. and Olshen, R. A.},
  series    = {The Wadsworth and Brooks-Cole statistics-probability series},
  year      = {1984},
  publisher = {Taylor \& Francis}
}

@article{marin2012approximate,
  title     = {Approximate Bayesian computational methods},
  author    = {Marin, Jean-Michel and Pudlo, Pierre and Robert, Christian P and Ryder, Robin J},
  journal   = {Statistics and Computing},
  volume    = {22},
  number    = {6},
  pages     = {1167--1180},
  year      = {2012},
  publisher = {Springer}
}

@article{pudlo2015reliable,
  title     = {Reliable ABC model choice via random forests},
  author    = {Pudlo, Pierre and Marin, Jean-Michel and Estoup, Arnaud and Cornuet, Jean-Marie and Gautier, Mathieu and Robert, Christian P},
  journal   = {Bioinformatics},
  volume    = {32},
  number    = {6},
  pages     = {859--866},
  year      = {2015},
  publisher = {Oxford University Press}
}

@article{raynal2016abc,
  author   = {Raynal, Louis and Marin, Jean-Michel and Pudlo, Pierre and Ribatet, Mathieu and Robert, Christian P and Estoup, Arnaud},
  title    = {{ABC random forests for Bayesian parameter inference}},
  journal  = {Bioinformatics},
  volume   = {35},
  number   = {10},
  pages    = {1720-1728},
  year     = {2018},
  month    = {10},
  abstract = {{Approximate Bayesian computation (ABC) has grown into a standard methodology that manages Bayesian inference for models associated with intractable likelihood functions. Most ABC implementations require the preliminary selection of a vector of informative statistics summarizing raw data. Furthermore, in almost all existing implementations, the tolerance level that separates acceptance from rejection of simulated parameter values needs to be calibrated.We propose to conduct likelihood-free Bayesian inferences about parameters with no prior selection of the relevant components of the summary statistics and bypassing the derivation of the associated tolerance level. The approach relies on the random forest (RF) methodology of Breiman (2001) applied in a (non-parametric) regression setting. We advocate the derivation of a new RF for each component of the parameter vector of interest. When compared with earlier ABC solutions, this method offers significant gains in terms of robustness to the choice of the summary statistics, does not depend on any type of tolerance level, and is a good trade-off in term of quality of point estimator precision and credible interval estimations for a given computing time. We illustrate the performance of our methodological proposal and compare it with earlier ABC methods on a Normal toy example and a population genetics example dealing with human population evolution.All methods designed here have been incorporated in the R package abcrf (version 1.7.1) available on CRAN.Supplementary data are available at Bioinformatics online.}},
  issn     = {1367-4803},
  doi      = {10.1093/bioinformatics/bty867},
  url      = {https://doi.org/10.1093/bioinformatics/bty867},
  eprint   = {http://oup.prod.sis.lan/bioinformatics/article-pdf/35/10/1720/28639964/bty867.pdf}
}

@article{wright2015ranger,
  title   = {Ranger: a fast implementation of random forests for high dimensional data in C++ and R},
  author  = {Wright, Marvin N and Ziegler, Andreas},
  journal = {arXiv preprint arXiv:1508.04409},
  year    = {2015}
}

@article{Athey_2019,
   title={Generalized random forests},
   volume={47},
   ISSN={0090-5364},
   url={http://dx.doi.org/10.1214/18-AOS1709},
   DOI={10.1214/18-aos1709},
   number={2},
   journal={The Annals of Statistics},
   publisher={Institute of Mathematical Statistics},
   author={Athey, Susan and Tibshirani, Julie and Wager, Stefan},
   year={2019},
   month={Apr},
   pages={1148â€“1178}
}

@article{hivert2018measuring,
  title={Measuring genetic differentiation from Pool-seq data},
  author={Hivert, Valentin and Leblois, Rapha{\"e}l and Petit, Eric J and Gautier, Mathieu and Vitalis, Renaud},
  journal={Genetics},
  volume={210},
  number={1},
  pages={315--330},
  year={2018},
  publisher={Genetics Soc America}
}

@book{friedman2001elements,
  title={The elements of statistical learning},
  author={Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert},
  volume={1},
  number={10},
  year={2001},
  publisher={Springer series in statistics New York, NY, USA:}
}

@Manual{marinraynal2019abcrf,
    title = {abcrf: Approximate Bayesian Computation via Random Forests},
    author = {Jean-Michel Marin and Louis Raynal and Pierre Pudlo and Christian P. Robert and Arnaud Estoup},
    year = {2019},
    note = {R package version 1.8.1},
    url = {https://CRAN.R-project.org/package=abcrf},
  }

  @article{meinshausen2006quantile,
  title={Quantile regression forests},
  author={Meinshausen, Nicolai},
  journal={Journal of Machine Learning Research},
  volume={7},
  number={Jun},
  pages={983--999},
  year={2006}
}

@article{lintusaari2018elfi,
  author  = {Jarno Lintusaari and Henri Vuollekoski and Antti Kangasr{\"a}{\"a}si{\"o} and Kusti Skyt{\'e}n and Marko J{\"a}rvenp{\"a}{\"a} and Pekka Marttinen and Michael U. Gutmann and Aki Vehtari and Jukka Corander and Samuel Kaski},
  title   = {ELFI: Engine for Likelihood-Free Inference},
  journal = {Journal of Machine Learning Research},
  year    = {2018},
  volume  = {19},
  number  = {16},
  pages   = {1-7},
  url     = {http://jmlr.org/papers/v19/17-374.html}
}

@inproceedings{ke2017lightgbm,
  title={Lightgbm: A highly efficient gradient boosting decision tree},
  author={Ke, Guolin and Meng, Qi and Finley, Thomas and Wang, Taifeng and Chen, Wei and Ma, Weidong and Ye, Qiwei and Liu, Tie-Yan},
  booktitle={Advances in neural information processing systems},
  pages={3146--3154},
  year={2017}
}

@inproceedings{kontschieder2015deep,
  title={Deep neural decision forests},
  author={Kontschieder, Peter and Fiterau, Madalina and Criminisi, Antonio and Rota Bulo, Samuel},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1467--1475},
  year={2015}
}